{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd       # For data manipulation\n",
    "import numpy as np        # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For basic plotting\n",
    "import seaborn as sns     # For advanced visualizations\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "from sklearn.linear_model import LinearRegression     # Example prediction model\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "file_path  = 'C:/Users/sande/OneDrive/Desktop/power BI/Stock Valuation Using Cash Flow Projections/Apple_Historical_Stock_Data.csv'\n",
    "file_path1 = 'C:/Users/sande/OneDrive/Desktop/power BI/Stock Valuation Using Cash Flow Projections/Apple_Income_Statement_10_Years.csv'\n",
    "file_path2 = 'C:/Users/sande/OneDrive/Desktop/power BI/Stock Valuation Using Cash Flow Projections/Balance_Sheet_10_Years.csv'\n",
    "file_path3 = 'C:/Users/sande/OneDrive/Desktop/power BI/Stock Valuation Using Cash Flow Projections/Cash_Flow_10_Years.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "df3 = pd.read_csv(file_path3)\n",
    "# Increase the number of columns displayed\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)       # Adjust display width for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date         0\n",
      "Adj Close    0\n",
      "Close        0\n",
      "High         0\n",
      "Low          0\n",
      "Open         0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3005 entries, 0 to 3004\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype              \n",
      "---  ------     --------------  -----              \n",
      " 0   Date       3005 non-null   datetime64[ns, UTC]\n",
      " 1   Adj Close  3005 non-null   float64            \n",
      " 2   Close      3005 non-null   float64            \n",
      " 3   High       3005 non-null   float64            \n",
      " 4   Low        3005 non-null   float64            \n",
      " 5   Open       3005 non-null   float64            \n",
      " 6   Volume     3005 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(5), int64(1)\n",
      "memory usage: 164.5 KB\n",
      "None\n",
      "         Adj Close        Close         High          Low         Open  \\\n",
      "count  3005.000000  3005.000000  3005.000000  3005.000000  3005.000000   \n",
      "mean     80.613575    82.775453    83.581238    81.887231    82.705906   \n",
      "std      65.568927    65.125907    65.736836    64.427632    65.052581   \n",
      "min      11.939034    13.947500    14.271429    13.753571    13.856071   \n",
      "25%      25.633987    28.230000    28.504999    27.915001    28.205000   \n",
      "50%      45.593632    47.860001    48.162498    47.544998    47.887501   \n",
      "75%     143.055847   145.429993   146.720001   143.250000   144.690002   \n",
      "max     246.750000   246.750000   247.240005   242.130005   243.990005   \n",
      "\n",
      "             Volume  \n",
      "count  3.005000e+03  \n",
      "mean   1.530598e+08  \n",
      "std    1.222073e+08  \n",
      "min    2.404830e+07  \n",
      "25%    7.685710e+07  \n",
      "50%    1.133164e+08  \n",
      "75%    1.860980e+08  \n",
      "max    1.460852e+09  \n",
      "updated dataframe saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-09 00:00:00+00:00</td>\n",
       "      <td>16.687342</td>\n",
       "      <td>19.608213</td>\n",
       "      <td>19.821428</td>\n",
       "      <td>19.343929</td>\n",
       "      <td>19.779285</td>\n",
       "      <td>560518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-06 00:00:00+00:00</td>\n",
       "      <td>16.476713</td>\n",
       "      <td>19.360714</td>\n",
       "      <td>19.631071</td>\n",
       "      <td>19.321428</td>\n",
       "      <td>19.567142</td>\n",
       "      <td>352965200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-05 00:00:00+00:00</td>\n",
       "      <td>16.017754</td>\n",
       "      <td>18.821428</td>\n",
       "      <td>19.236786</td>\n",
       "      <td>18.779642</td>\n",
       "      <td>19.177500</td>\n",
       "      <td>594333600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-04 00:00:00+00:00</td>\n",
       "      <td>15.923534</td>\n",
       "      <td>18.710714</td>\n",
       "      <td>18.903570</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>18.642857</td>\n",
       "      <td>484156400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-03 00:00:00+00:00</td>\n",
       "      <td>15.966394</td>\n",
       "      <td>18.761070</td>\n",
       "      <td>18.996071</td>\n",
       "      <td>18.616072</td>\n",
       "      <td>18.900356</td>\n",
       "      <td>458707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>2013-01-08 00:00:00+00:00</td>\n",
       "      <td>242.649994</td>\n",
       "      <td>242.649994</td>\n",
       "      <td>242.759995</td>\n",
       "      <td>238.899994</td>\n",
       "      <td>239.809998</td>\n",
       "      <td>38861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>2013-01-07 00:00:00+00:00</td>\n",
       "      <td>243.009995</td>\n",
       "      <td>243.009995</td>\n",
       "      <td>244.110001</td>\n",
       "      <td>241.250000</td>\n",
       "      <td>242.869995</td>\n",
       "      <td>44383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>2013-01-04 00:00:00+00:00</td>\n",
       "      <td>243.039993</td>\n",
       "      <td>243.039993</td>\n",
       "      <td>244.539993</td>\n",
       "      <td>242.130005</td>\n",
       "      <td>243.990005</td>\n",
       "      <td>40033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>2013-01-03 00:00:00+00:00</td>\n",
       "      <td>242.839996</td>\n",
       "      <td>242.839996</td>\n",
       "      <td>244.630005</td>\n",
       "      <td>242.080002</td>\n",
       "      <td>242.910004</td>\n",
       "      <td>36870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>2013-01-02 00:00:00+00:00</td>\n",
       "      <td>246.750000</td>\n",
       "      <td>246.750000</td>\n",
       "      <td>247.240005</td>\n",
       "      <td>241.750000</td>\n",
       "      <td>241.830002</td>\n",
       "      <td>44649200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3005 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date   Adj Close       Close        High  \\\n",
       "0    2024-12-09 00:00:00+00:00   16.687342   19.608213   19.821428   \n",
       "1    2024-12-06 00:00:00+00:00   16.476713   19.360714   19.631071   \n",
       "2    2024-12-05 00:00:00+00:00   16.017754   18.821428   19.236786   \n",
       "3    2024-12-04 00:00:00+00:00   15.923534   18.710714   18.903570   \n",
       "4    2024-12-03 00:00:00+00:00   15.966394   18.761070   18.996071   \n",
       "...                        ...         ...         ...         ...   \n",
       "3000 2013-01-08 00:00:00+00:00  242.649994  242.649994  242.759995   \n",
       "3001 2013-01-07 00:00:00+00:00  243.009995  243.009995  244.110001   \n",
       "3002 2013-01-04 00:00:00+00:00  243.039993  243.039993  244.539993   \n",
       "3003 2013-01-03 00:00:00+00:00  242.839996  242.839996  244.630005   \n",
       "3004 2013-01-02 00:00:00+00:00  246.750000  246.750000  247.240005   \n",
       "\n",
       "             Low        Open     Volume  \n",
       "0      19.343929   19.779285  560518000  \n",
       "1      19.321428   19.567142  352965200  \n",
       "2      18.779642   19.177500  594333600  \n",
       "3      18.400000   18.642857  484156400  \n",
       "4      18.616072   18.900356  458707200  \n",
       "...          ...         ...        ...  \n",
       "3000  238.899994  239.809998   38861000  \n",
       "3001  241.250000  242.869995   44383900  \n",
       "3002  242.130005  243.990005   40033900  \n",
       "3003  242.080002  242.910004   36870600  \n",
       "3004  241.750000  241.830002   44649200  \n",
       "\n",
       "[3005 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the df Apple_Historical_Stock_Data.csv \n",
    "\n",
    "print(df.isnull().sum())\n",
    "#df[' Volume '] = df[' Volume '].str.strip() #to remove extra spaces\n",
    "#df[' Volume '] = df[' Volume '].str.replace(',', '', regex=False)   # to replace commas between the numerics \n",
    "#df[' Volume '] = pd.to_numeric(df[' Volume '])\n",
    "df['Date'] = pd.to_datetime(df['Date'],errors='coerce')\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "# Save the DataFrame back to the original CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "print('updated dataframe saved')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and filtering the apple_Income_Statement_10_Years.csv\n",
    "# Clean column names to remove leading/trailing spaces\n",
    "df1.columns = df1.columns.str.strip()\n",
    "\n",
    "# Drop unwanted columns ( 'Unnamed' columns)\n",
    "df1 = df1.drop(columns=[], axis=1, errors='ignore')\n",
    "\n",
    "# Convert 'fiscalDateEnding' to datetime, handling errors gracefully\n",
    "df1['fiscalDateEnding'] = pd.to_datetime(df1['fiscalDateEnding'], errors='coerce')\n",
    "\n",
    "# Replace 'None' and '_' with 0 in the entire DataFrame\n",
    "df1 = df1.replace(['None', '0', '  None  ', '  -    '], 0)\n",
    "\n",
    "df1 = df1.fillna(0)\n",
    "\n",
    "# List of columns to process\n",
    "columns_to_clean = ['grossProfit', 'totalRevenue', 'costOfRevenue', 'costofGoodsAndServicesSold', 'operatingIncome', 'sellingGeneralAndAdministrative', 'researchAndDevelopment',\n",
    "       'operatingExpenses', 'investmentIncomeNet', 'netInterestIncome', 'interestIncome', 'interestExpense', 'nonInterestIncome', 'otherNonOperatingIncome', 'depreciation',\n",
    "       'depreciationAndAmortization', 'incomeBeforeTax', 'incomeTaxExpense', 'interestAndDebtExpense', 'netIncomeFromContinuingOperations',\n",
    "       'comprehensiveIncomeNetOfTax', 'ebit', 'ebitda', 'netIncome']\n",
    "\n",
    "# Loop through the selected columns\n",
    "for col in columns_to_clean:\n",
    "    # Remove commas and convert to integer\n",
    "    df1[col] = df1[col].str.replace(',', '', regex=False)\n",
    "    df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
    "\n",
    "df1.to_csv(file_path1, index=False)\n",
    "print('updated dataframe saved')\n",
    "df1.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and filtering the Balance_Sheet_10_Years.csv\n",
    "# Clean column names to remove leading/trailing spaces\n",
    "df2.columns = df2.columns.str.strip()\n",
    "\n",
    "# Drop unwanted columns ( 'treasuryStock' column in this case)\n",
    "df2 = df2.drop(columns=['treasuryStock'], axis=1, errors='ignore')\n",
    "\n",
    "# Drop rows with NaN values, reassigning the updated DataFrame\n",
    "df2 = df2.dropna()\n",
    "\n",
    "# Convert 'fiscalDateEnding' to datetime, handling errors gracefully\n",
    "df2['fiscalDateEnding'] = pd.to_datetime(df2['fiscalDateEnding'], errors='coerce')\n",
    "\n",
    "# Replace 'None', '0', and other placeholders with 0 in the entire DataFrame\n",
    "df2 = df2.replace(['None', '0', '  None  ', '  -    '], 0)\n",
    "\n",
    "# List of columns to process (numerical columns with commas)\n",
    "columns_to_clean1 = ['totalAssets', 'totalCurrentAssets', 'cashAndCashEquivalentsAtCarryingValue', \n",
    "                     'cashAndShortTermInvestments', 'inventory', 'currentNetReceivables',\n",
    "                     'totalNonCurrentAssets', 'propertyPlantEquipment', 'accumulatedDepreciationAmortizationPPE', \n",
    "                     'intangibleAssets', 'intangibleAssetsExcludingGoodwill', 'goodwill', 'investments', \n",
    "                     'longTermInvestments', 'shortTermInvestments', 'otherCurrentAssets', 'otherNonCurrentAssets', \n",
    "                     'totalLiabilities', 'totalCurrentLiabilities', 'currentAccountsPayable', 'deferredRevenue', \n",
    "                     'currentDebt', 'shortTermDebt', 'totalNonCurrentLiabilities', 'capitalLeaseObligations',\n",
    "                     'longTermDebt', 'currentLongTermDebt', 'longTermDebtNoncurrent', 'shortLongTermDebtTotal', \n",
    "                     'otherCurrentLiabilities', 'otherNonCurrentLiabilities', 'totalShareholderEquity', 'retainedEarnings', \n",
    "                     'commonStock', 'commonStockSharesOutstanding']\n",
    "\n",
    "# Loop through the selected columns\n",
    "for col in columns_to_clean1:\n",
    "    # Convert the column to string (if not already)\n",
    "    df2[col] = df2[col].astype(str)\n",
    "    \n",
    "    # Remove commas from the string values and convert to numeric\n",
    "    df2[col] = df2[col].str.replace(',', '', regex=False)\n",
    "    \n",
    "    # Convert the cleaned column to numeric, errors='coerce' will convert invalid parsing into NaN\n",
    "    df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "\n",
    "# Optionally, replace NaN values with 0 or another placeholder if needed\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "# Display the cleaned DataFrame and its data types\n",
    "df2.info()\n",
    "\n",
    "df2.to_csv(file_path2,index=False)\n",
    "print('Updated data successfully')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cash_Flow_10_Years.csv data cleaning\n",
    "# Clean column names to remove leading/trailing spaces\n",
    "df3.columns = df3.columns.str.strip()\n",
    "\n",
    "# Drop unwanted columns ( 'treasuryStock' column in this case)\n",
    "df3 = df3.drop(columns=['proceedsFromOperatingActivities','paymentsForRepurchaseOfPreferredStock','dividendPayoutPreferredStock','proceedsFromIssuanceOfPreferredStock','proceedsFromSaleOfTreasuryStock','changeInExchangeRate','Unnamed: 29','Unnamed: 30'],axis=1,errors='ignore')\n",
    "\n",
    "\n",
    "# Drop rows with NaN values, reassigning the updated DataFrame\n",
    "df3= df3.dropna()\n",
    "\n",
    "# Convert 'fiscalDateEnding' to datetime, handling errors gracefully\n",
    "df3['fiscalDateEnding'] = pd.to_datetime(df3['fiscalDateEnding'], errors='coerce')\n",
    "\n",
    "# Replace 'None', '0', and other placeholders with 0 in the entire DataFrame\n",
    "df3 = df3.replace([' None ', '0', '  None  ', ' -   '], 0)\n",
    "\n",
    "columns_to_clean2 =[ 'operatingCashflow',\n",
    "       'paymentsForOperatingActivities', 'changeInOperatingLiabilities',\n",
    "       'changeInOperatingAssets', 'depreciationDepletionAndAmortization',\n",
    "       'capitalExpenditures', 'changeInReceivables', 'changeInInventory',\n",
    "       'profitLoss', 'cashflowFromInvestment', 'cashflowFromFinancing',\n",
    "       'proceedsFromRepaymentsOfShortTermDebt',\n",
    "       'paymentsForRepurchaseOfCommonStock', 'paymentsForRepurchaseOfEquity',\n",
    "       'dividendPayout', 'dividendPayoutCommonStock',\n",
    "       'proceedsFromIssuanceOfCommonStock',\n",
    "       'proceedsFromIssuanceOfLongTermDebtAndCapitalSecuritiesNet',\n",
    "       'proceedsFromRepurchaseOfEquity', 'changeInCashAndCashEquivalents',\n",
    "       'netIncome']\n",
    "\n",
    "# Loop through the selected columns\n",
    "for col in columns_to_clean2:\n",
    "    # Convert the column to string (if not already)\n",
    "    df3[col] = df3[col].astype(str)\n",
    "    \n",
    "    # Remove commas from the string values and convert to numeric\n",
    "    df3[col] = df3[col].str.replace(',', '', regex=False)\n",
    "    \n",
    "    # Convert the cleaned column to numeric, errors='coerce' will convert invalid parsing into NaN\n",
    "    df3[col] = pd.to_numeric(df3[col], errors='coerce')\n",
    "\n",
    "# Optionally, replace NaN values with 0 or another placeholder if needed\n",
    "df3 = df3.fillna(0)\n",
    "\n",
    "# Display the cleaned DataFrame and its data types\n",
    "df3.to_csv(file_path3,index=False)\n",
    "print('Updated data successfully')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of a numerical column (replace 'column_name' with your actual column name)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(data['column_name'], kde=True, color='blue')  # Replace 'column_name'\n",
    "plt.title(\"Distribution of Column\")\n",
    "plt.show()\n",
    "\n",
    "# Pairplot for relationships between numerical columns\n",
    "sns.pairplot(data)\n",
    "plt.show()\n",
    "\n",
    "# Data Cleaning and Preparation\n",
    "# Fill missing values (example: mean for numerical columns)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Feature Selection/Engineering (if needed)\n",
    "\n",
    "# Splitting the dataset into training and testing sets for predictions\n",
    "# Replace 'target_column' with your actual target column\n",
    "X = data.drop('target_column', axis=1)  # Features\n",
    "y = data['target_column']  # Target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "model = LinearRegression()  # Example regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nMean Squared Error: {mse}\")\n",
    "print(f\"R-Squared Value: {r2}\")\n",
    "\n",
    "# Plotting Actual vs Predicted\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='blue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
